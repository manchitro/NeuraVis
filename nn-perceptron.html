<!DOCTYPE html>
<html lang="en">
	<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-0LCX0TLTK4"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag() {
				dataLayer.push(arguments);
			}
			gtag("js", new Date());

			gtag("config", "G-0LCX0TLTK4");
		</script>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Perceptrons</title>
		<link rel="preconnect" href="https://fonts.gstatic.com" />
		<link href="https://fonts.googleapis.com/css2?family=Montserrat&display=swap" rel="stylesheet" />
		<link rel="stylesheet" href="assets/css/style.css" />
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous" />
		<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
		<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
		<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" integrity="sha384-w1Q4orYjBQndcko6MimVbzY0tgp4pWB4lZ7lr30WKz0vr/aWKhXdBNmNb5D92v7s" crossorigin="anonymous"></script>
		<script src="./assets/js/include.js"></script>
		<link rel="icon" type="image/png" href="assets/images/favicon.png" />
	</head>
	<body>
		<script>
			include("./partials/nav.html", document.currentScript);
		</script>
		<script src="./assets/js/active.js"></script>
		<div role="main" class="container-sm my-4 border-dark border-right border-left">
			<h1 class="mb-2">Perceptrons</h1>
			<p class="">Revisiting the decision making example from the <a href="nn-intro.html">Intro to Neural Networks</a> section, we can build a simple neural network that looks like this:</p>
			<img src="./assets/images/trip_decision-01.jpg" class="mw-100 h-auto" alt="" />
			<p>
				This network takes three yes/no (binary) input and decides wether you want to go on the trip or not. The righmost neuron here is a Perceptron. (Note that, the inputs are not perceptrons but are drawn like one) <br />
				Perceptrons take some binary input and outputs a binary number (yes/no). Each input has a weight indicating the importance relative to other inputs that can alter the final output. <br />
				This is what a single perceptron looks like:
			</p>
			<img src="./assets/images/rsz_perceptron-01.jpg" class="mw-100 h-auto" alt="" />
			<p>
				Here, <strong>x<sub>1</sub>, x<sub>2</sub> and x<sub>3</sub></strong> are inputs for our perceptron and <strong>w<sub>1</sub>, w<sub>2</sub> and w<sub>3</sub></strong> are weights of the corresponding input. <br /><br />
				There is one property of a perceptron that we haven't yet talked about. It's called <strong>bias</strong>. Just as inputs have weights, the perceptron itself has a bias. Bias is a number that decides how likely the perceptron is to produce an affirmative output. It can be compared to the trip decision making network as "how likely you are to go on a trip in general". Then no matter what the inputs and their weights are, the possibility of you going on a trip greatly increases if your bias is high. To completely understand how the output is calculated, we need to get into some math. So buckle up!
			</p>
			<p>Output of a perceptron is binary (1 or 0 / yes or no) and it is calculated as follows:</p>
			<p>1. First we calculate the weighted sum of the inputs (multiply weight with corresponding input values and add all of them together)</p>
			<div class="math w-75 mx-auto mb-3">(x<sub>1</sub>*w<sub>1</sub>) + (x<sub>2</sub>*w<sub>2</sub>) + (x<sub>3</sub>*w<sub>3</sub>)</div>
			<p>2. Then we add the bias (denoted as b)</p>
			<div class="math w-75 mx-auto mb-3">(x<sub>1</sub>*w<sub>1</sub>) + (x<sub>2</sub>*w<sub>2</sub>) + (x<sub>3</sub>*w<sub>3</sub>) + b</div>
			<p>3. Lastly we compare if the value of this expression is greater than 0 or not. If it is the output of the perceptron is 1, otherwise 0</p>
			<div class="math w-75 mx-auto mb-3">
				if (x<sub>1</sub>*w<sub>1</sub>) + (x<sub>2</sub>*w<sub>2</sub>) + (x<sub>3</sub>*w<sub>3</sub>) + b > 0 , output = 1 <br />
				if (x<sub>1</sub>*w<sub>1</sub>) + (x<sub>2</sub>*w<sub>2</sub>) + (x<sub>3</sub>*w<sub>3</sub>) + b <= 0 , output = 0
			</div>
			<p>From this inequality, we can see that if bias is higher, the more it is likely to produce 1 as a output.</p>
			<p>Since not all perceptrons have 3 inputs, we can write a generalized formula that is independent of number of inputs:</p>
			<div class="math w-75 mx-auto mb-3">
				If ∑<sub>j</sub>w<sub>j</sub>x<sub>j</sub> + b > 0 , output = 1 <br />
				if ∑<sub>j</sub>w<sub>j</sub>x<sub>j</sub> + b <= 0 , output = 0
			</div>
			<p>Here, j is the number of inputs.</p>

			<div class="page-nav d-flex flex-row justify-content-between">
				<a href="nn-intro.html">< Previous</a>
				<a href="nn-sigmoid.html">Next ></a>
			</div>
		</div>
		<script>
			include("./partials/footer.html", document.currentScript);
		</script>
	</body>
</html>
